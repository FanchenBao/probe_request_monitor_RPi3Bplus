# Introduction
This is a proof of concept build for using Raspberry Pi's own WiFi chip to do probe request sniffing, and upload the sniffing result to a s3 bucket on aws. 

# Usage
## 1. Enable Monitor Mode on RPi's WiFi chip

In order to perform probe request sniffing, RPi's WiFi chip must have monitor mode enabled. Since this is by default disabled by RPi's firmware, a firmware patch must be done first. We have performed a firmware patch following the instructions from [nexmon](https://github.com/seemoo-lab/nexmon). The RPi we use for this build is 3B+ model, running Raspbian kernel 4.19, and using firmware version 7.45.154. Following is the procedures we use to do the firmware patch.

1. A fresh install of Raspbian Buster Lite image (follow this [official doc](https://www.raspberrypi.org/documentation/installation/installing-images/) and this [tutorial](https://hackernoon.com/raspberry-pi-headless-install-462ccabd75d0) for headless Pi setup), kernel version 4.19. 
2. After a headless installation, SSH to the Pi and do not change any settings.
3. Run `dmesg | grep brcmfmac` to confirm WiFi chip's firmware version (our version is `7.45.154`). The `nexmon` firmware patch depends on the firmware version.
4. Install the following dependencies
    1. `sudo apt-get install autoconf`
    2. `sudo apt-get install libtool`
    3. `sudo apt-get install texinfo`
    4. `sudo apt-get install tcpdump`
5. Follow [nexmon patch for Raspberry Pi](https://github.com/seemoo-lab/nexmon#build-patches-for-bcm43430a1-on-the-rpi3zero-w-or-bcm434355c0-on-the-rpi3rpi4-using-raspbian-recommended). Two things to note:
    1. Both `libisl.so.10` and `libmpfr.so.4` need to be compiled. Before compiling `libmpfr.so.4`, one must run `autoreconf -f -i` to resolve some issue (similar to this [question](https://stackoverflow.com/questions/33278928/how-to-overcome-aclocal-1-15-is-missing-on-your-system-warning) on SO)
    2. Go to `nexmon/patches/bcm43455c0/7_45_154/nexmon/` for the proper firmware patch.
6. After running `ifconfig mon0 up`, if `tcpdump -i mon0` returns info, that means the patch has been successful. Another way to notice whether `mon0` is up is to run `iwconfig` and see whether `mon0` has a field called `Tx-Power=?? dBm`. If this field exists, `mon0` is up, otherwise `mon0` is configured but not up.

## 2. Set up AWS Environment
* Register an account on aws if you haven't already and create a s3 bucket for storing data.
* Go through [this tutorials](https://docs.aws.amazon.com/iot/latest/developerguide/iot-plant-module1.html) for setting up aws iot and make appropriate modifications when necessary.
	* In step 2 of the tutorial, generate certificates for connecting your RPi to a shadow client on aws iot and place them in the `keys` directory.
	* In step 4 of the tutorial, make the following changes:
	  * For item 5 "rule query statement", use this statement `SELECT VALUE state.reported.data FROM "$aws/things/RPi_3Bplus_WPB_test/shadow/update/accepted"`
	  * For item 7 "select an action", choose "Store a message in an Amazon S3 bucket". In the "Keys" blank, fill in `${state.reported.timestamp}.csv`

## 3. Run Script on RPi
* Download this repository and install the Python dependencies via `pip3 install -r requirements.txt`. We recommend that you create a virtual environment before installing the dependencies.
* Run `./start_up.sh`. This will do two things. First, it turns on `mon0` if it is not on already, and start monitoring probe request using an open source tool [sniff-probes](https://github.com/brannondorsey/sniff-probes) (located within the `sniff-probes` directory). Second, it runs an uploading service in the background, which automatically connects to aws iot shadow client via the certificates stored in `keys` directory, and send probe requests data as MQTT message. The messages sent to aws iot will trigger an action to store the messages in a predefined s3 bucket.
* User can configure how long each monitoring session should be. For example, `./start_up.sh -p 30` means to let each monitoring session be 30 seconds, and restart again. The benefit of making monitoring into sessions is that the data collected can be dumped in small chunks. This prevents potential data loss due to monitoring malfunction, and make data upload to cloud much easier. If a flag is not used, the default monitoring session length is 60 seconds.

# Things Worth Noting
1. Monitoring produces `monitor.log` in `sniff-probes` directory. It records all the information generated by this open source tool during operation.
2. Uploading service from `upload_s3.py` also generates `transmit.log`, which records information related to the well-being of the uploading service.
3. Data generated by `sniff-probes` are stored in `sniff-probes` directory first. After a monitoring session is over, the data file is transferred to `data` directory, waiting to be uploaded to s3 bucket.
4. Uploading service can automatically detect internet connection. If internet connection does not exist or is lost during normal operation, uploading service would shut down by itself without affecting monitoring (i.e. monitoring conitnues despite internet connection situation). Once internet connection is back on, uploading service would automatically reconnect to aws iot and resume uploading.